# Otimiza√ß√µes de Performance

Este documento detalha as otimiza√ß√µes implementadas no sistema de processamento de editais.

## Resumo das Otimiza√ß√µes

1. ‚úÖ **Processamento Paralelo de M√∫ltiplos PDFs**
2. ‚úÖ **Batch Inserts no Supabase**
3. ‚úÖ **Cache de Resultados LLM**
4. ‚úÖ **Async I/O para Chamadas LLM e DB**
5. ‚úÖ **Connection Pooling no Supabase**

---

## 1. Processamento Paralelo de M√∫ltiplos PDFs

### Implementa√ß√£o
- **Arquivo**: `main.py:298-315`
- **Estrat√©gia**: Processamento em batches de at√© 3 PDFs simult√¢neos usando `asyncio.gather()`
- **Benef√≠cio**: Reduz tempo total ao processar m√∫ltiplos editais

### Configura√ß√£o
```python
max_concurrent = 3  # Ajuste conforme recursos dispon√≠veis
```

### Ganho Estimado
- **3 PDFs**: ~70% mais r√°pido (tempo/3 vs tempo*3)
- **10 PDFs**: ~65% mais r√°pido

---

## 2. Batch Inserts no Supabase

### Implementa√ß√£o
- **Arquivo**: `src/database/supabase_client.py:136-169`
- **Estrat√©gia**: Inser√ß√£o em lotes de 100 registros por vez
- **Benef√≠cio**: Reduz lat√™ncia de rede e overhead de conex√µes HTTP

### Configura√ß√£o
```python
await db.inserir_conteudo_programatico(conteudos, batch_size=100)
```

### Ganho Estimado
- **1000 registros**: ~90% mais r√°pido (10 requests vs 1000)
- **5000 registros**: ~98% mais r√°pido (50 requests vs 5000)

---

## 3. Cache de Resultados LLM

### Implementa√ß√£o
- **Arquivo**: `src/utils/llm_cache.py`
- **Estrat√©gia**: Cache persistente em disco usando `diskcache` com TTL de 24h
- **Chave**: Hash SHA-256 de `{modelo}|{system_prompt}|{prompt}`
- **Benef√≠cio**: Evita chamadas duplicadas √† LLM (custo e lat√™ncia)

### Configura√ß√£o
```python
# Habilitar/desabilitar cache
llm_client = OpenRouterClient(cache_enabled=True, cache_ttl=86400)

# Limpar cache
llm_client.cache.clear()

# Ver estat√≠sticas
stats = llm_client.get_cache_stats()
```

### Diret√≥rio de Cache
```
.cache/llm/  # Cache persistente entre execu√ß√µes
```

### Ganho Estimado
- **Edital duplicado**: ~100% economia (sem custo LLM)
- **Reprocessamento**: At√© 95% mais r√°pido

---

## 4. Async I/O para LLM e DB

### Implementa√ß√£o

#### LLM Client (`src/processors/llm_client.py`)
- Usa `AsyncOpenAI` da biblioteca openai
- Timeout configurado: 60s
- Max retries: 2

#### Supabase Client (`src/database/supabase_client.py`)
- Usa `httpx.AsyncClient` para chamadas REST ass√≠ncronas
- Todas as opera√ß√µes convertidas para async/await

#### EditalProcessor (`main.py:23-149`)
- M√©todo `process()` convertido para async
- **Paraleliza√ß√£o interna**: Chamadas LLM de metadados e verticaliza√ß√£o executam em paralelo (linha 96)
- **Paraleliza√ß√£o de inserts**: Cargos e conte√∫do program√°tico inseridos em paralelo (linha 120)

### Benef√≠cio
- Chamadas LLM executam simultaneamente (economia de ~50% no tempo de LLM)
- Inserts no banco executam simultaneamente
- CPU n√£o fica bloqueada esperando I/O

### Ganho Estimado
- **Chamadas LLM paralelas**: ~40-50% mais r√°pido por edital
- **Inserts paralelos**: ~30% mais r√°pido

---

## 5. Connection Pooling no Supabase

### Implementa√ß√£o
- **Arquivo**: `src/database/supabase_client.py:23-36`
- **Cliente**: `httpx.AsyncClient` com limits configurados

### Configura√ß√£o
```python
SupabaseManager(
    pool_size=10,           # M√°ximo de conex√µes simult√¢neas
    max_keepalive=5         # Conex√µes mantidas vivas
)
```

### Benef√≠cio
- Reutiliza conex√µes HTTP
- Reduz overhead de handshake TCP/TLS
- Melhora throughput em opera√ß√µes batch

### Ganho Estimado
- **M√∫ltiplas requisi√ß√µes**: ~20-30% mais r√°pido
- **Batch operations**: ~15% mais r√°pido

---

## Ganhos Totais Estimados

### Cen√°rio 1: Processamento de 1 edital
- Chamadas LLM paralelas: **-40%**
- Cache (reprocessamento): **-95%**
- Connection pooling: **-15%**
- **Total**: ~50-60% mais r√°pido (primeiro processamento)
- **Total (reprocessamento)**: ~95% mais r√°pido

### Cen√°rio 2: Processamento de 10 editais
- Processamento paralelo (3x): **-65%**
- Async I/O: **-40%**
- Batch inserts: **-90%**
- Connection pooling: **-20%**
- **Total**: ~70-80% mais r√°pido

### Economia de Custos
- Cache LLM evita chamadas duplicadas
- **Hit rate de 30%**: ~30% de economia em custos de LLM
- **Hit rate de 70%**: ~70% de economia

---

## Monitoramento de Performance

### Estat√≠sticas de Cache
Execute o sistema e veja as estat√≠sticas ao final:

```
üíæ Cache LLM:
  Hits: 15
  Misses: 5
  Taxa de acerto: 75.00%
  Tamanho: 20 entradas
```

### Logs de Tempo
O sistema registra automaticamente:
- Tempo de extra√ß√£o de PDF
- Tempo de chamadas LLM
- Tempo total de processamento

---

## Configura√ß√µes Recomendadas

### Para Desenvolvimento Local
```python
max_concurrent = 2          # N√£o sobrecarregar CPU local
pool_size = 5              # Conex√µes moderadas
cache_ttl = 3600           # 1h (testes r√°pidos)
```

### Para Produ√ß√£o
```python
max_concurrent = 5          # Aproveitar recursos do servidor
pool_size = 20             # Maior throughput
cache_ttl = 86400          # 24h (economia m√°xima)
```

### Para Processamento em Massa
```python
max_concurrent = 10         # M√°xima paraleliza√ß√£o
pool_size = 30             # Alta concorr√™ncia
batch_size = 200           # Batches maiores
```

---

## Pr√≥ximos Passos (Futuras Otimiza√ß√µes)

1. **C√°lculo real de custo por modelo**: Implementar tracking preciso baseado em tokens
2. **Rate limiting inteligente**: Respeitar limites de API do OpenRouter
3. **M√©tricas detalhadas**: Adicionar OpenTelemetry para observabilidade
4. **Compress√£o de texto**: Comprimir texto extra√≠do antes de enviar para LLM
5. **Streaming de respostas LLM**: Processar resposta enquanto ainda est√° sendo gerada
6. **Pool de workers**: Distribuir processamento entre m√∫ltiplos processos Python

---

## Depend√™ncias Adicionais

```txt
aiofiles>=23.0.0          # Async file I/O
aiocache>=0.12.0          # Cache async com TTL
diskcache>=5.6.0          # Cache persistente em disco
```

Instale com:
```bash
uv pip install -r requirements.txt
```

---

## Uso

```bash
# Processar editais no diret√≥rio input_pdfs/
python main.py

# Uso program√°tico
import asyncio
from main import EditalProcessor

async def processar():
    processor = EditalProcessor()
    success = await processor.process('input_pdfs/edital.pdf')
    await processor.db.close()

asyncio.run(processar())
```